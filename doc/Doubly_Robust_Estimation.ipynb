{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5243 Project 4 Doubly Robust Estimations(without scale)\n",
    "\n",
    "## Group3 - Zi Fang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "# set seed\n",
    "random_state = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowdim_data = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "highdim_data = pd.read_csv('../data/highDim_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_param(data, random_state, param_grid, cv=10):\n",
    "    '''\n",
    "    Purpose: to find the best parameter \"C\" (coefficient of regularization strength) for the specific dataset\n",
    "    \n",
    "    Parameters:\n",
    "    data - dataset to best tested on \n",
    "    random_state - set seed\n",
    "    param_grid - set of parameter values to test on\n",
    "    cv - number of folds for cross-validation\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = data.drop(['A','Y'], axis = 1)  \n",
    "    y = data[['A']].values.ravel()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    model_cv = GridSearchCV(LogisticRegression(penalty='l1',solver = 'liblinear'), param_grid, cv=cv)\n",
    "    model_cv.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"The best tuned coefficient of regularization strength is\",model_cv.best_params_.get('C'), \n",
    "          \"with a testing accuracy of\", model_cv.score(x_test, y_test))\n",
    "    \n",
    "    return model_cv.best_params_.get('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score(data, C=0.1, plot = True):\n",
    "    '''\n",
    "    Purpose: to estimate propensity score with L1 penalized logistic regression\n",
    "    \n",
    "    Parameters:\n",
    "    data - dataset to estimate on \n",
    "    C - coeficient of regularization strength\n",
    "    plot - print out visualization to show distribution of propensity scores\n",
    "    \n",
    "    Returns:\n",
    "    1. ps for Propensity Score\n",
    "    2. Visualization plot to show distribution of propensity scores\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    T = 'A'\n",
    "    Y = 'Y'\n",
    "    X = data.columns.drop([T,Y])\n",
    "    \n",
    "    ps_model = LogisticRegression(random_state=random_state, penalty='l1',\n",
    "                                  solver='liblinear').fit(data[X], data[T]) \n",
    "    \n",
    "    ps = ps_model.predict_proba(data[X])[:,1] # we are interested in the probability of getting a \"1\"\n",
    "    \n",
    "    if plot:\n",
    "        df_plot = pd.DataFrame({'Treatment':data[T], 'Propensity Score':ps})\n",
    "        \n",
    "        sns.histplot(data=df_plot, x = \"Propensity Score\", hue = \"Treatment\", element = \"step\")\n",
    "        plt.title(\"Distribution of Propensity Score by Treatment Group\", size=20)\n",
    "        plt.show()\n",
    "   \n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "param_grid = {\"C\":[0.01,0.05,0.1,0.3,0.5,0.7,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Dimensional Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best tuned coefficient of regularization strength is 0.3 with a testing accuracy of 0.8\n"
     ]
    }
   ],
   "source": [
    "# use 10-fold cross-validation to tune for the best parameter for logistic regression\n",
    "DR_low_start = time.time()\n",
    "c_low = best_param(lowdim_data, random_state=random_state, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate propensity score for low dimensional case\n",
    "PS_low = propensity_score(lowdim_data, C = c_low, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data, add propensity score column and divide data into treat and control groups\n",
    "lowdim_data_new = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "lowdim_data_new['PS_low'] = pd.Series(PS_low, index=lowdim_data_new.index)\n",
    "lowdim_treat = lowdim_data[lowdim_data['A'] == 1].reset_index(drop = True)\n",
    "lowdim_control = lowdim_data[lowdim_data['A'] == 0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit regression models to treat and control group\n",
    "xlow_treat = lowdim_treat.drop(['A','Y'],axis=1)\n",
    "ylow_treat = lowdim_treat['Y']\n",
    "lr_low_treat = LinearRegression().fit(xlow_treat, ylow_treat)\n",
    "\n",
    "xlow_control = lowdim_control.drop(['A','Y'],axis=1)\n",
    "ylow_control = lowdim_control['Y']\n",
    "lr_low_control = LinearRegression().fit(xlow_control, ylow_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction based on trained models and construct a full dataset \n",
    "xlow = lowdim_data_new.drop(['A','Y','PS_low'],axis=1)\n",
    "lowdim_data_new['mtreat'] = lr_low_treat.predict(xlow)\n",
    "lowdim_data_new['mcontrol'] = lr_low_control.predict(xlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Doubly Robust Estimation algorithm\n",
    "DR_low_1 = 0\n",
    "DR_low_0 = 0\n",
    "    \n",
    "for i in range(len(lowdim_data_new)):\n",
    "    DR_low_1 = DR_low_1 + (lowdim_data_new['A'][i] * lowdim_data_new['Y'][i] - (lowdim_data_new['A'][i] - lowdim_data_new['PS_low'][i])*lowdim_data_new['mtreat'][i])/lowdim_data_new['PS_low'][i]\n",
    "    DR_low_0 = DR_low_0 + ((1-lowdim_data_new['A'][i])* lowdim_data_new['Y'][i] + (lowdim_data_new['A'][i] - lowdim_data_new['PS_low'][i])*lowdim_data_new['mcontrol'][i])/(1-lowdim_data_new['PS_low'][i])\n",
    "        \n",
    "DR_low_ETA = (DR_low_1 - DR_low_0)/len(lowdim_data_new)\n",
    "DR_low_accu = 1 - abs((DR_low_ETA -2.0901)/2.0901)\n",
    "DR_low_end = time.time()\n",
    "DR_low_time = DR_low_end - DR_low_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly robust estimation method for low dimensional dataset:\n",
      " ETA = 2.090\n",
      " Accuracy = 1.000\n",
      " DR running time = 0.749\n"
     ]
    }
   ],
   "source": [
    "# print the ETA, accuracy and algorithm running time results\n",
    "print(f'Doubly robust estimation method for low dimensional dataset:\\n ETA = {DR_low_ETA:0.3f}\\n Accuracy = {DR_low_accu:0.3f}\\n DR running time = {DR_low_time:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Dimensional Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best tuned coefficient of regularization strength is 0.01 with a testing accuracy of 0.71\n"
     ]
    }
   ],
   "source": [
    "# use 10-fold cross-validation to tune for the best parameter for logistic regression\n",
    "DR_high_start = time.time()\n",
    "c_high = best_param(highdim_data, random_state=random_state, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate propensity score for high dimensional case\n",
    "PS_high = propensity_score(highdim_data, C = c_high, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data, add propensity score column and divide data into treat and control groups\n",
    "highdim_data_new = pd.read_csv('../data/highDim_dataset.csv')\n",
    "highdim_data_new['PS_high'] = pd.Series(PS_high, index=highdim_data.index)\n",
    "highdim_treat = highdim_data[highdim_data.A == 1].reset_index(drop = True)\n",
    "highdim_control = highdim_data[highdim_data.A == 0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit regression model to treat and control group\n",
    "xhigh_treat = highdim_treat.drop(['A','Y'],axis=1)\n",
    "yhigh_treat = highdim_treat['Y']\n",
    "lr_high_treat = LinearRegression().fit(xhigh_treat, yhigh_treat)\n",
    "\n",
    "xhigh_control = highdim_control.drop(['A','Y'],axis=1)\n",
    "yhigh_control = highdim_control['Y']\n",
    "lr_high_control = LinearRegression().fit(xhigh_control, yhigh_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction based on trained models and construct a full dataset \n",
    "xhigh = highdim_data_new.drop(['A','Y','PS_high'],axis=1)\n",
    "highdim_data_new['mtreat'] = lr_high_treat.predict(xhigh)\n",
    "highdim_data_new['mcontrol'] = lr_high_control.predict(xhigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Doubly Robust Estimation algorithm\n",
    "DR_high_1 = 0\n",
    "DR_high_0 = 0\n",
    "    \n",
    "for i in range(len(highdim_data_new)):\n",
    "    DR_high_1 = DR_high_1 + (highdim_data_new['A'][i] * highdim_data_new['Y'][i] - (highdim_data_new['A'][i]- highdim_data_new['PS_high'][i])*highdim_data_new['mtreat'][i])/highdim_data_new['PS_high'][i]\n",
    "    DR_high_0 = DR_high_0 + ((1-highdim_data_new['A'][i])* highdim_data_new['Y'][i] + (highdim_data_new['A'][i] - highdim_data_new['PS_high'][i])*highdim_data_new['mcontrol'][i])/(1-highdim_data_new['PS_high'][i])\n",
    "\n",
    "DR_high_ETA = (DR_high_1 - DR_high_0)/len(highdim_data_new)\n",
    "DR_high_accu = 1 - abs((DR_high_ETA -(-54.8558))/(-54.8558))\n",
    "DR_high_end = time.time()\n",
    "DR_high_time = DR_high_end - DR_high_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly robust estimation method for high dimensional dataset:\n",
      " ETA = -56.622\n",
      " Accuracy = 0.968\n",
      " DR running time = 85.069\n"
     ]
    }
   ],
   "source": [
    "# print the ETA, accuracy and algorithm running time result\n",
    "print(f'Doubly robust estimation method for high dimensional dataset:\\n ETA = {DR_high_ETA:0.3f}\\n Accuracy = {DR_high_accu:0.3f}\\n DR running time = {DR_high_time:0.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-s21",
   "language": "python",
   "name": "eods-s21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
