{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5243 Project 4 Doubly Robust Estimations(Scaled)\n",
    "\n",
    "## Group3 - Zi Fang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "# set seed\n",
    "random_state = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowdim_data = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "highdim_data = pd.read_csv('../data/highDim_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scale the datasets\n",
    "def scaled_data(data):\n",
    "    x = data.drop(['A','Y'], axis = 1)\n",
    "    y = data[[\"A\"]]\n",
    "    \n",
    "    data_columns = data.columns.drop(['Y','A'])\n",
    "    \n",
    "    x_scaled = StandardScaler().fit_transform(x)\n",
    "    \n",
    "    data_scaled = pd.DataFrame(x_scaled, index = data.index, columns = data_columns)\n",
    "    \n",
    "    data_scaled['A'] = data['A']\n",
    "    data_scaled['Y'] = data['Y']\n",
    "    \n",
    "    display(data_scaled.head())\n",
    "    \n",
    "    return data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V178</th>\n",
       "      <th>V179</th>\n",
       "      <th>V180</th>\n",
       "      <th>V181</th>\n",
       "      <th>V182</th>\n",
       "      <th>V183</th>\n",
       "      <th>V184</th>\n",
       "      <th>V185</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.015114</td>\n",
       "      <td>0.482748</td>\n",
       "      <td>-1.161393</td>\n",
       "      <td>0.303352</td>\n",
       "      <td>1.487812</td>\n",
       "      <td>-1.171070</td>\n",
       "      <td>-1.423520</td>\n",
       "      <td>1.686961</td>\n",
       "      <td>1.203321</td>\n",
       "      <td>0.382352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140538</td>\n",
       "      <td>-0.061157</td>\n",
       "      <td>-0.096027</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.078727</td>\n",
       "      <td>-0.092975</td>\n",
       "      <td>-0.065612</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>0</td>\n",
       "      <td>41.224513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.015114</td>\n",
       "      <td>-2.071474</td>\n",
       "      <td>-1.650640</td>\n",
       "      <td>-1.477143</td>\n",
       "      <td>-0.512424</td>\n",
       "      <td>-1.171070</td>\n",
       "      <td>0.204290</td>\n",
       "      <td>0.524392</td>\n",
       "      <td>1.203321</td>\n",
       "      <td>0.801943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208702</td>\n",
       "      <td>-0.099379</td>\n",
       "      <td>-0.208780</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.078727</td>\n",
       "      <td>-0.092975</td>\n",
       "      <td>-0.065612</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>0</td>\n",
       "      <td>40.513875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.015114</td>\n",
       "      <td>-2.071474</td>\n",
       "      <td>0.795598</td>\n",
       "      <td>-1.922267</td>\n",
       "      <td>-0.876103</td>\n",
       "      <td>-0.415004</td>\n",
       "      <td>-0.880917</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>1.203321</td>\n",
       "      <td>-0.037239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447277</td>\n",
       "      <td>-0.443385</td>\n",
       "      <td>-0.434284</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.078727</td>\n",
       "      <td>-0.092975</td>\n",
       "      <td>-0.065612</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>0</td>\n",
       "      <td>38.495476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985111</td>\n",
       "      <td>-2.071474</td>\n",
       "      <td>-1.324475</td>\n",
       "      <td>-1.477143</td>\n",
       "      <td>-1.239782</td>\n",
       "      <td>-1.171070</td>\n",
       "      <td>-0.700049</td>\n",
       "      <td>0.698777</td>\n",
       "      <td>-0.831034</td>\n",
       "      <td>-0.456829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447277</td>\n",
       "      <td>-0.443385</td>\n",
       "      <td>-0.434284</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.078727</td>\n",
       "      <td>-0.092975</td>\n",
       "      <td>-0.065612</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>0</td>\n",
       "      <td>33.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.985111</td>\n",
       "      <td>0.482748</td>\n",
       "      <td>-0.019815</td>\n",
       "      <td>0.971038</td>\n",
       "      <td>0.214934</td>\n",
       "      <td>0.492274</td>\n",
       "      <td>2.012968</td>\n",
       "      <td>0.756906</td>\n",
       "      <td>1.203321</td>\n",
       "      <td>0.382352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174620</td>\n",
       "      <td>-0.137602</td>\n",
       "      <td>-0.133612</td>\n",
       "      <td>1.226231</td>\n",
       "      <td>1.319316</td>\n",
       "      <td>1.105593</td>\n",
       "      <td>1.180743</td>\n",
       "      <td>1.396247</td>\n",
       "      <td>0</td>\n",
       "      <td>37.043603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.015114  0.482748 -1.161393  0.303352  1.487812 -1.171070 -1.423520   \n",
       "1 -1.015114 -2.071474 -1.650640 -1.477143 -0.512424 -1.171070  0.204290   \n",
       "2 -1.015114 -2.071474  0.795598 -1.922267 -0.876103 -0.415004 -0.880917   \n",
       "3  0.985111 -2.071474 -1.324475 -1.477143 -1.239782 -1.171070 -0.700049   \n",
       "4  0.985111  0.482748 -0.019815  0.971038  0.214934  0.492274  2.012968   \n",
       "\n",
       "         V8        V9       V10  ...      V178      V179      V180      V181  \\\n",
       "0  1.686961  1.203321  0.382352  ... -0.140538 -0.061157 -0.096027 -0.051378   \n",
       "1  0.524392  1.203321  0.801943  ... -0.208702 -0.099379 -0.208780 -0.051378   \n",
       "2  0.669713  1.203321 -0.037239  ... -0.447277 -0.443385 -0.434284 -0.051378   \n",
       "3  0.698777 -0.831034 -0.456829  ... -0.447277 -0.443385 -0.434284 -0.051378   \n",
       "4  0.756906  1.203321  0.382352  ... -0.174620 -0.137602 -0.133612  1.226231   \n",
       "\n",
       "       V182      V183      V184      V185  A          Y  \n",
       "0 -0.078727 -0.092975 -0.065612 -0.053082  0  41.224513  \n",
       "1 -0.078727 -0.092975 -0.065612 -0.053082  0  40.513875  \n",
       "2 -0.078727 -0.092975 -0.065612 -0.053082  0  38.495476  \n",
       "3 -0.078727 -0.092975 -0.065612 -0.053082  0  33.001889  \n",
       "4  1.319316  1.105593  1.180743  1.396247  0  37.043603  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scale the high dimentional dataset\n",
    "highdim_scale_data = scaled_data(highdim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.502205</td>\n",
       "      <td>-0.352816</td>\n",
       "      <td>-0.257883</td>\n",
       "      <td>-0.266592</td>\n",
       "      <td>-0.34195</td>\n",
       "      <td>-0.465776</td>\n",
       "      <td>-0.266412</td>\n",
       "      <td>-0.649809</td>\n",
       "      <td>-0.35092</td>\n",
       "      <td>-0.159096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.868574</td>\n",
       "      <td>-0.181992</td>\n",
       "      <td>-0.739177</td>\n",
       "      <td>-0.107309</td>\n",
       "      <td>-0.285789</td>\n",
       "      <td>-0.217729</td>\n",
       "      <td>5.769470</td>\n",
       "      <td>0.184432</td>\n",
       "      <td>0</td>\n",
       "      <td>30.486999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.502205</td>\n",
       "      <td>-0.352816</td>\n",
       "      <td>-0.257883</td>\n",
       "      <td>-0.266592</td>\n",
       "      <td>-0.34195</td>\n",
       "      <td>-0.465776</td>\n",
       "      <td>-0.266412</td>\n",
       "      <td>1.034631</td>\n",
       "      <td>-0.35092</td>\n",
       "      <td>-0.159096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143710</td>\n",
       "      <td>-0.181992</td>\n",
       "      <td>0.443696</td>\n",
       "      <td>-0.107309</td>\n",
       "      <td>-0.285789</td>\n",
       "      <td>-0.217729</td>\n",
       "      <td>-0.335214</td>\n",
       "      <td>2.374539</td>\n",
       "      <td>0</td>\n",
       "      <td>18.208417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.502205</td>\n",
       "      <td>-0.352816</td>\n",
       "      <td>-0.257883</td>\n",
       "      <td>-0.266592</td>\n",
       "      <td>-0.34195</td>\n",
       "      <td>-0.465776</td>\n",
       "      <td>-0.266412</td>\n",
       "      <td>-0.649809</td>\n",
       "      <td>-0.35092</td>\n",
       "      <td>-0.159096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979830</td>\n",
       "      <td>-0.181992</td>\n",
       "      <td>-0.739177</td>\n",
       "      <td>-0.107309</td>\n",
       "      <td>-0.285789</td>\n",
       "      <td>-0.217729</td>\n",
       "      <td>-0.335214</td>\n",
       "      <td>-1.264176</td>\n",
       "      <td>0</td>\n",
       "      <td>13.485040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.441468</td>\n",
       "      <td>-0.352816</td>\n",
       "      <td>-0.257883</td>\n",
       "      <td>-0.266592</td>\n",
       "      <td>-0.34195</td>\n",
       "      <td>-0.465776</td>\n",
       "      <td>-0.266412</td>\n",
       "      <td>-0.649809</td>\n",
       "      <td>-0.35092</td>\n",
       "      <td>-0.159096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363695</td>\n",
       "      <td>-0.181992</td>\n",
       "      <td>1.271707</td>\n",
       "      <td>-0.107309</td>\n",
       "      <td>-0.285789</td>\n",
       "      <td>-0.217729</td>\n",
       "      <td>-0.335214</td>\n",
       "      <td>-0.753260</td>\n",
       "      <td>1</td>\n",
       "      <td>25.699678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253654</td>\n",
       "      <td>0.209949</td>\n",
       "      <td>-0.150877</td>\n",
       "      <td>-0.081459</td>\n",
       "      <td>-0.34195</td>\n",
       "      <td>0.445723</td>\n",
       "      <td>0.162041</td>\n",
       "      <td>0.493204</td>\n",
       "      <td>1.15826</td>\n",
       "      <td>-0.071411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767548</td>\n",
       "      <td>-0.181992</td>\n",
       "      <td>0.595779</td>\n",
       "      <td>-0.107309</td>\n",
       "      <td>1.061785</td>\n",
       "      <td>0.282464</td>\n",
       "      <td>-0.335214</td>\n",
       "      <td>0.719985</td>\n",
       "      <td>0</td>\n",
       "      <td>23.752968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4       V5        V6        V7  \\\n",
       "0 -0.502205 -0.352816 -0.257883 -0.266592 -0.34195 -0.465776 -0.266412   \n",
       "1 -0.502205 -0.352816 -0.257883 -0.266592 -0.34195 -0.465776 -0.266412   \n",
       "2 -0.502205 -0.352816 -0.257883 -0.266592 -0.34195 -0.465776 -0.266412   \n",
       "3  3.441468 -0.352816 -0.257883 -0.266592 -0.34195 -0.465776 -0.266412   \n",
       "4 -0.253654  0.209949 -0.150877 -0.081459 -0.34195  0.445723  0.162041   \n",
       "\n",
       "         V8       V9       V10  ...       V15       V16       V17       V18  \\\n",
       "0 -0.649809 -0.35092 -0.159096  ... -0.868574 -0.181992 -0.739177 -0.107309   \n",
       "1  1.034631 -0.35092 -0.159096  ... -0.143710 -0.181992  0.443696 -0.107309   \n",
       "2 -0.649809 -0.35092 -0.159096  ...  0.979830 -0.181992 -0.739177 -0.107309   \n",
       "3 -0.649809 -0.35092 -0.159096  ...  0.363695 -0.181992  1.271707 -0.107309   \n",
       "4  0.493204  1.15826 -0.071411  ...  0.767548 -0.181992  0.595779 -0.107309   \n",
       "\n",
       "        V19       V20       V21       V22  A          Y  \n",
       "0 -0.285789 -0.217729  5.769470  0.184432  0  30.486999  \n",
       "1 -0.285789 -0.217729 -0.335214  2.374539  0  18.208417  \n",
       "2 -0.285789 -0.217729 -0.335214 -1.264176  0  13.485040  \n",
       "3 -0.285789 -0.217729 -0.335214 -0.753260  1  25.699678  \n",
       "4  1.061785  0.282464 -0.335214  0.719985  0  23.752968  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scale the low dimentional dataset\n",
    "lowdim_scale_data = scaled_data(lowdim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_param(data, random_state, param_grid, cv=10):\n",
    "    '''\n",
    "    Purpose: to find the best parameter \"C\" (coefficient of regularization strength) for the specific dataset\n",
    "    \n",
    "    Parameters:\n",
    "    data - dataset to best tested on \n",
    "    random_state - set seed\n",
    "    param_grid - set of parameter values to test on\n",
    "    cv - number of folds for cross-validation\n",
    "    \n",
    "    '''\n",
    "\n",
    "    x = data.drop(['A','Y'], axis = 1)  \n",
    "    y = data[['A']].values.ravel()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    model_cv = GridSearchCV(LogisticRegression(penalty='l1',solver = 'liblinear'), param_grid, cv=cv)\n",
    "    model_cv.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"The best tuned coefficient of regularization strength is\",model_cv.best_params_.get('C'), \n",
    "          \"with a testing accuracy of\", model_cv.score(x_test, y_test))\n",
    "    \n",
    "    return model_cv.best_params_.get('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score(data, C=0.1, plot = True):\n",
    "    '''\n",
    "    Purpose: to estimate propensity score with L1 penalized logistic regression\n",
    "    \n",
    "    Parameters:\n",
    "    data - dataset to estimate on \n",
    "    C - coeficient of regularization strength\n",
    "    plot - print out visualization to show distribution of propensity scores\n",
    "    \n",
    "    Returns:\n",
    "    1. ps for Propensity Score\n",
    "    2. Visualization plot to show distribution of propensity scores\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    T = 'A'\n",
    "    Y = 'Y'\n",
    "    X = data.columns.drop([T,Y])\n",
    "    \n",
    "    ps_model = LogisticRegression(random_state=random_state, penalty='l1',\n",
    "                                  solver='liblinear').fit(data[X], data[T]) \n",
    "    \n",
    "    ps = ps_model.predict_proba(data[X])[:,1] # we are interested in the probability of getting a \"1\"\n",
    "    \n",
    "    if plot:\n",
    "        df_plot = pd.DataFrame({'Treatment':data[T], 'Propensity Score':ps})\n",
    "        \n",
    "        sns.histplot(data=df_plot, x = \"Propensity Score\", hue = \"Treatment\", element = \"step\")\n",
    "        plt.title(\"Distribution of Propensity Score by Treatment Group\", size=20)\n",
    "        plt.show()\n",
    "   \n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "param_grid = {\"C\":[0.01,0.05,0.1,0.3,0.5,0.7,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Dimensional Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best tuned coefficient of regularization strength is 0.3 with a testing accuracy of 0.792\n"
     ]
    }
   ],
   "source": [
    "# use 10-fold cross-validation to tune for the best parameter for logistic regression\n",
    "DR_low_start = time.time()\n",
    "c_low = best_param(lowdim_scale_data, random_state=random_state, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate propensity score for low dimensional case\n",
    "PS_low = propensity_score(lowdim_scale_data, C = c_low, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data, add propensity score column and divide data into treat and control groups\n",
    "lowdim_data_new = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "lowdim_data_new['PS_low'] = pd.Series(PS_low, index=lowdim_data_new.index)\n",
    "lowdim_treat = lowdim_data[lowdim_data['A'] == 1].reset_index(drop = True)\n",
    "lowdim_control = lowdim_data[lowdim_data['A'] == 0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit regression models to treat and control group\n",
    "xlow_treat = lowdim_treat.drop(['A','Y'],axis=1)\n",
    "ylow_treat = lowdim_treat['Y']\n",
    "lr_low_treat = LinearRegression().fit(xlow_treat, ylow_treat)\n",
    "\n",
    "xlow_control = lowdim_control.drop(['A','Y'],axis=1)\n",
    "ylow_control = lowdim_control['Y']\n",
    "lr_low_control = LinearRegression().fit(xlow_control, ylow_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction based on trained models and construct a full dataset \n",
    "xlow = lowdim_data_new.drop(['A','Y','PS_low'],axis=1)\n",
    "lowdim_data_new['mtreat'] = lr_low_treat.predict(xlow)\n",
    "lowdim_data_new['mcontrol'] = lr_low_control.predict(xlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Doubly Robust Estimation algorithm\n",
    "DR_low_1 = 0\n",
    "DR_low_0 = 0\n",
    "    \n",
    "for i in range(len(lowdim_data_new)):\n",
    "    DR_low_1 = DR_low_1 + (lowdim_data_new['A'][i] * lowdim_data_new['Y'][i] - (lowdim_data_new['A'][i] - lowdim_data_new['PS_low'][i])*lowdim_data_new['mtreat'][i])/lowdim_data_new['PS_low'][i]\n",
    "    DR_low_0 = DR_low_0 + ((1-lowdim_data_new['A'][i])* lowdim_data_new['Y'][i] + (lowdim_data_new['A'][i] - lowdim_data_new['PS_low'][i])*lowdim_data_new['mcontrol'][i])/(1-lowdim_data_new['PS_low'][i])\n",
    "        \n",
    "DR_low_ETA = (DR_low_1 - DR_low_0)/len(lowdim_data_new)\n",
    "DR_low_accu = 1 - abs((DR_low_ETA -2.0901)/2.0901)\n",
    "DR_low_end = time.time()\n",
    "DR_low_time = DR_low_end - DR_low_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly robust estimation method for low dimensional dataset:\n",
      " ETA = 2.085\n",
      " Accuracy = 0.998\n",
      " DR running time = 0.644\n"
     ]
    }
   ],
   "source": [
    "# print the ETA, accuracy and algorithm running time results\n",
    "print(f'Doubly robust estimation method for low dimensional dataset:\\n ETA = {DR_low_ETA:0.3f}\\n Accuracy = {DR_low_accu:0.3f}\\n DR running time = {DR_low_time:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Dimensional Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best tuned coefficient of regularization strength is 0.05 with a testing accuracy of 0.716\n"
     ]
    }
   ],
   "source": [
    "# use 10-fold cross-validation to tune for the best parameter for logistic regression\n",
    "DR_high_start = time.time()\n",
    "c_high = best_param(highdim_scale_data, random_state=random_state, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate propensity score for high dimensional case\n",
    "PS_high = propensity_score(highdim_scale_data, C = c_high, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data, add propensity score column and divide data into treat and control groups\n",
    "highdim_data_new = pd.read_csv('../data/highDim_dataset.csv')\n",
    "highdim_data_new['PS_high'] = pd.Series(PS_high, index=highdim_data.index)\n",
    "highdim_treat = highdim_data[highdim_data.A == 1].reset_index(drop = True)\n",
    "highdim_control = highdim_data[highdim_data.A == 0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit regression model to treat and control group\n",
    "xhigh_treat = highdim_treat.drop(['A','Y'],axis=1)\n",
    "yhigh_treat = highdim_treat['Y']\n",
    "lr_high_treat = LinearRegression().fit(xhigh_treat, yhigh_treat)\n",
    "\n",
    "xhigh_control = highdim_control.drop(['A','Y'],axis=1)\n",
    "yhigh_control = highdim_control['Y']\n",
    "lr_high_control = LinearRegression().fit(xhigh_control, yhigh_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction based on trained models and construct a full dataset \n",
    "xhigh = highdim_data_new.drop(['A','Y','PS_high'],axis=1)\n",
    "highdim_data_new['mtreat'] = lr_high_treat.predict(xhigh)\n",
    "highdim_data_new['mcontrol'] = lr_high_control.predict(xhigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Doubly Robust Estimation algorithm\n",
    "DR_high_1 = 0\n",
    "DR_high_0 = 0\n",
    "    \n",
    "for i in range(len(highdim_data_new)):\n",
    "    DR_high_1 = DR_high_1 + (highdim_data_new['A'][i] * highdim_data_new['Y'][i] - (highdim_data_new['A'][i]- highdim_data_new['PS_high'][i])*highdim_data_new['mtreat'][i])/highdim_data_new['PS_high'][i]\n",
    "    DR_high_0 = DR_high_0 + ((1-highdim_data_new['A'][i])* highdim_data_new['Y'][i] + (highdim_data_new['A'][i] - highdim_data_new['PS_high'][i])*highdim_data_new['mcontrol'][i])/(1-highdim_data_new['PS_high'][i])\n",
    "\n",
    "DR_high_ETA = (DR_high_1 - DR_high_0)/len(highdim_data_new)\n",
    "DR_high_accu = 1 - abs((DR_high_ETA -(-54.8558))/(-54.8558))\n",
    "DR_high_end = time.time()\n",
    "DR_high_time = DR_high_end - DR_high_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly robust estimation method for high dimensional dataset:\n",
      " ETA = -57.038\n",
      " Accuracy = 0.960\n",
      " DR running time = 15.592\n"
     ]
    }
   ],
   "source": [
    "# print the ETA, accuracy and algorithm running time result\n",
    "print(f'Doubly robust estimation method for high dimensional dataset:\\n ETA = {DR_high_ETA:0.3f}\\n Accuracy = {DR_high_accu:0.3f}\\n DR running time = {DR_high_time:0.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-s21",
   "language": "python",
   "name": "eods-s21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
